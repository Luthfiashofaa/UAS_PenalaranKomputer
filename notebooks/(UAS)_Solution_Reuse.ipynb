{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luthfiashofaa/UAS_PenalaranKomputer/blob/main/(UAS)_Solution_Reuse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tahap 4 - Solution Reuse"
      ],
      "metadata": {
        "id": "vPLrKA_uLvuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz8WNBqMMs45",
        "outputId": "dba519b5-0772-49df-f4c2-14fdf55f8073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Counter\n",
        "from collections import Counter, defaultdict\n",
        "import logging\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# BERT and Transformers\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModel\n",
        "    import torch\n",
        "    TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Transformers not available. Install with: pip install transformers torch\")\n",
        "    TRANSFORMERS_AVAILABLE = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmiLlvJLFxgq",
        "outputId": "ecaaaac2-79cd-42c2-ec6e-da1a68f4732c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ekstrak Solusi"
      ],
      "metadata": {
        "id": "8bUpieCjLywa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i. EKSTRAK SOLUSI\n",
        "# 1. Dari kasus top-k, ambil amar putusan atau ringkasan dakwaan\n",
        "# 2. Simpan di struktur: {case_id: solusi_text}\n",
        "# ============================================================================\n",
        "\n",
        "class RetrievalSystem:\n",
        "    \"\"\"\n",
        "    Sistem retrieval untuk mendukung solution reuse\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/korupsi\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.vectors_dir = os.path.join(base_dir, \"data\", \"vectors\")\n",
        "\n",
        "        # Components\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.case_vectors_tfidf = None\n",
        "        self.case_ids = []\n",
        "\n",
        "        self.load_components()\n",
        "\n",
        "    def load_components(self) -> bool:\n",
        "        \"\"\"Load retrieval components\"\"\"\n",
        "        print(\"üîç Loading retrieval components...\")\n",
        "\n",
        "        # Find best vector file\n",
        "        vector_files = [f for f in os.listdir(self.vectors_dir) if f.endswith('.pkl')]\n",
        "\n",
        "        best_file = None\n",
        "        best_vocab_size = 0\n",
        "\n",
        "        for vf in vector_files:\n",
        "            if 'tfidf' in vf.lower():\n",
        "                try:\n",
        "                    with open(os.path.join(self.vectors_dir, vf), 'rb') as f:\n",
        "                        data = pickle.load(f)\n",
        "\n",
        "                    if 'vectorizer' in data:\n",
        "                        vocab_size = len(data['vectorizer'].get_feature_names_out())\n",
        "                        if vocab_size > best_vocab_size:\n",
        "                            best_vocab_size = vocab_size\n",
        "                            best_file = vf\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        if best_file:\n",
        "            file_path = os.path.join(self.vectors_dir, best_file)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "\n",
        "            self.tfidf_vectorizer = data['vectorizer']\n",
        "            self.case_vectors_tfidf = data['vectors']\n",
        "            self.case_ids = data['case_ids']\n",
        "\n",
        "            if hasattr(self.case_vectors_tfidf, 'toarray'):\n",
        "                self.case_vectors_tfidf = self.case_vectors_tfidf.toarray()\n",
        "\n",
        "            print(f\"‚úÖ Loaded: {len(self.case_ids)} cases, {best_vocab_size:,} vocab\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 5) -> List[str]:\n",
        "        \"\"\"Retrieve top-k similar cases\"\"\"\n",
        "        if not self.tfidf_vectorizer or self.case_vectors_tfidf is None:\n",
        "            return []\n",
        "\n",
        "        # Preprocess query\n",
        "        processed_query = query.lower().strip()\n",
        "        processed_query = re.sub(r'\\s+', ' ', processed_query)\n",
        "\n",
        "        # Compute query vector\n",
        "        query_vector = self.tfidf_vectorizer.transform([processed_query])\n",
        "\n",
        "        if query_vector.nnz == 0:\n",
        "            return []\n",
        "\n",
        "        # Compute similarities\n",
        "        query_dense = query_vector.toarray() if hasattr(query_vector, 'toarray') else query_vector\n",
        "        similarities = cosine_similarity(query_dense, self.case_vectors_tfidf).flatten()\n",
        "\n",
        "        # Return top-k case_ids\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "        return [self.case_ids[idx] for idx in top_indices]\n",
        "\n",
        "    def retrieve_with_scores(self, query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"Retrieve with similarity scores\"\"\"\n",
        "        if not self.tfidf_vectorizer or self.case_vectors_tfidf is None:\n",
        "            return []\n",
        "\n",
        "        processed_query = query.lower().strip()\n",
        "        query_vector = self.tfidf_vectorizer.transform([processed_query])\n",
        "\n",
        "        if query_vector.nnz == 0:\n",
        "            return []\n",
        "\n",
        "        query_dense = query_vector.toarray() if hasattr(query_vector, 'toarray') else query_vector\n",
        "        similarities = cosine_similarity(query_dense, self.case_vectors_tfidf).flatten()\n",
        "\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            case_id = self.case_ids[idx]\n",
        "            score = similarities[idx]\n",
        "            results.append((case_id, float(score)))\n",
        "\n",
        "        return results\n",
        "\n",
        "class SolutionExtractor:\n",
        "    \"\"\"\n",
        "    i. Ekstrak Solusi dari kasus top-k\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/korupsi\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.raw_dir = os.path.join(base_dir, \"CLEANED\")\n",
        "        self.processed_dir = os.path.join(base_dir, \"data\", \"processed\")\n",
        "\n",
        "        # Storage untuk solusi\n",
        "        self.case_solutions = {}  # {case_id: solusi_text}\n",
        "        self.case_metadata = {}\n",
        "\n",
        "        print(\"üìÑ i. EKSTRAK SOLUSI\")\n",
        "\n",
        "    def load_case_metadata(self) -> bool:\n",
        "        \"\"\"Load metadata kasus dari cases.csv\"\"\"\n",
        "        cases_file = os.path.join(self.processed_dir, \"cases.csv\")\n",
        "\n",
        "        if not os.path.exists(cases_file):\n",
        "            print(\"‚ùå cases.csv not found\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(cases_file, encoding='utf-8')\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                filename = row['nama_file']\n",
        "                case_id = filename.replace('.txt', '') if filename.endswith('.txt') else filename\n",
        "\n",
        "                self.case_metadata[case_id] = {\n",
        "                    'putusan': row.get('putusan', ''),\n",
        "                    'jenis_perkara': row.get('jenis_perkara', ''),\n",
        "                    'vonis': row.get('vonis', ''),\n",
        "                    'hukuman_pidana': row.get('hukuman_pidana', ''),\n",
        "                    'hukuman_denda': row.get('hukuman_denda', ''),\n",
        "                    'dakwaan': row.get('dakwaan', ''),\n",
        "                    'pasal_yang_dilanggar': row.get('pasal_yang_dilanggar', '')\n",
        "                }\n",
        "\n",
        "            print(f\"‚úÖ Loaded metadata for {len(self.case_metadata)} cases\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading metadata: {e}\")\n",
        "            return False\n",
        "\n",
        "    def extract_solution_from_text(self, text: str) -> str:\n",
        "        \"\"\"Ekstrak amar putusan atau ringkasan dari teks\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Pattern untuk mencari amar putusan\n",
        "        putusan_patterns = [\n",
        "            r'(amar\\s+putusan[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(mengadili[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(memutuskan[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(menjatuhkan\\s+pidana[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(menghukum\\s+terdakwa[:\\s].*?)(?:\\n\\n|\\Z)'\n",
        "        ]\n",
        "\n",
        "        # Cari pattern putusan\n",
        "        for pattern in putusan_patterns:\n",
        "            matches = re.findall(pattern, text_lower, re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                solution = matches[0].strip()\n",
        "                # Bersihkan dan ambil bagian penting\n",
        "                solution = re.sub(r'\\s+', ' ', solution)\n",
        "                solution = solution[:500]  # Batasi panjang\n",
        "                return solution\n",
        "\n",
        "        # Fallback: cari kalimat dengan kata kunci hukuman\n",
        "        hukuman_patterns = [\n",
        "            r'([^.]*(?:hukuman|pidana|denda|penjara|kurungan)[^.]*\\.)',\n",
        "            r'([^.]*(?:vonis|putusan|memutuskan)[^.]*\\.)',\n",
        "            r'([^.]*(?:terbukti|tidak terbukti)[^.]*\\.)'\n",
        "        ]\n",
        "\n",
        "        for pattern in hukuman_patterns:\n",
        "            matches = re.findall(pattern, text_lower)\n",
        "            if matches:\n",
        "                return matches[0].strip()[:300]\n",
        "\n",
        "        # Fallback terakhir: ambil bagian tengah dokumen\n",
        "        lines = text.split('\\n')\n",
        "        middle_start = len(lines) // 3\n",
        "        middle_end = 2 * len(lines) // 3\n",
        "        middle_text = ' '.join(lines[middle_start:middle_end])\n",
        "\n",
        "        return middle_text[:200].strip()\n",
        "\n",
        "    def create_solution_from_metadata(self, case_id: str) -> str:\n",
        "        \"\"\"Buat solusi dari metadata yang tersedia\"\"\"\n",
        "        if case_id not in self.case_metadata:\n",
        "            return \"Solusi tidak tersedia\"\n",
        "\n",
        "        meta = self.case_metadata[case_id]\n",
        "        solution_parts = []\n",
        "\n",
        "        # Jenis perkara\n",
        "        if meta['jenis_perkara']:\n",
        "            solution_parts.append(f\"Jenis: {meta['jenis_perkara']}\")\n",
        "\n",
        "        # Putusan\n",
        "        if meta['putusan']:\n",
        "            solution_parts.append(f\"Putusan: {meta['putusan']}\")\n",
        "\n",
        "        # Vonis\n",
        "        if meta['vonis']:\n",
        "            solution_parts.append(f\"Vonis: {meta['vonis']}\")\n",
        "\n",
        "        # Hukuman\n",
        "        if meta['hukuman_pidana']:\n",
        "            solution_parts.append(f\"Hukuman: {meta['hukuman_pidana']}\")\n",
        "\n",
        "        if meta['hukuman_denda']:\n",
        "            solution_parts.append(f\"Denda: {meta['hukuman_denda']}\")\n",
        "\n",
        "        # Pasal\n",
        "        if meta['pasal_yang_dilanggar']:\n",
        "            solution_parts.append(f\"Pasal: {meta['pasal_yang_dilanggar']}\")\n",
        "\n",
        "        if solution_parts:\n",
        "            return \"; \".join(solution_parts)\n",
        "        else:\n",
        "            return \"Informasi putusan tidak lengkap\"\n",
        "\n",
        "    def extract_all_solutions(self, case_ids: List[str]) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        1. Dari kasus top-k, ambil amar putusan atau ringkasan dakwaan\n",
        "        2. Simpan di struktur: {case_id: solusi_text}\n",
        "        \"\"\"\n",
        "        print(f\"\\nüìÑ Extracting solutions for {len(case_ids)} cases...\")\n",
        "\n",
        "        # Load metadata\n",
        "        self.load_case_metadata()\n",
        "\n",
        "        solutions = {}\n",
        "\n",
        "        for case_id in case_ids:\n",
        "            try:\n",
        "                # Strategy 1: Extract from raw text\n",
        "                raw_file = os.path.join(self.raw_dir, f\"{case_id}.txt\")\n",
        "\n",
        "                if os.path.exists(raw_file):\n",
        "                    with open(raw_file, 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "\n",
        "                    solution = self.extract_solution_from_text(text)\n",
        "\n",
        "                    if len(solution.strip()) > 20:  # Valid solution\n",
        "                        solutions[case_id] = solution\n",
        "                        continue\n",
        "\n",
        "                # Strategy 2: Use metadata\n",
        "                solution = self.create_solution_from_metadata(case_id)\n",
        "                solutions[case_id] = solution\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error extracting solution for {case_id}: {e}\")\n",
        "                solutions[case_id] = \"Solusi tidak dapat diekstrak\"\n",
        "\n",
        "        print(f\"‚úÖ Extracted {len(solutions)} solutions\")\n",
        "\n",
        "        # Show sample solutions\n",
        "        sample_cases = list(solutions.keys())[:3]\n",
        "        for case_id in sample_cases:\n",
        "            solution = solutions[case_id]\n",
        "            short_solution = solution[:100] + \"...\" if len(solution) > 100 else solution\n",
        "            print(f\"   {case_id}: {short_solution}\")\n",
        "\n",
        "        self.case_solutions = solutions\n",
        "        return solutions\n"
      ],
      "metadata": {
        "id": "4rpu0x2kDZmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritma Prediksi dan Implementasi Fungsi\n"
      ],
      "metadata": {
        "id": "70c2s4E2KQZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ii. ALGORITMA PREDIKSI\n",
        "# 1. Majority vote: pilih solusi yang paling banyak muncul\n",
        "# 2. Weighted similarity: bobot = skor similarity\n",
        "# ============================================================================\n",
        "\n",
        "class SolutionPredictor:\n",
        "    \"\"\"\n",
        "    ii. Algoritma Prediksi & iii. Implementasi Fungsi\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/korupsi\"):\n",
        "        self.base_dir = base_dir\n",
        "\n",
        "        # Components\n",
        "        self.retrieval_system = RetrievalSystem(base_dir)\n",
        "        self.solution_extractor = SolutionExtractor(base_dir)\n",
        "\n",
        "        # Cache all solutions untuk efisiensi\n",
        "        self._initialize_solution_cache()\n",
        "\n",
        "        print(\"üîÆ ii. ALGORITMA PREDIKSI\")\n",
        "\n",
        "    def _initialize_solution_cache(self):\n",
        "        \"\"\"Initialize cache dengan semua solusi yang tersedia\"\"\"\n",
        "        print(\"üíæ Initializing solution cache...\")\n",
        "\n",
        "        if self.retrieval_system.case_ids:\n",
        "            # Extract solutions untuk semua cases\n",
        "            all_solutions = self.solution_extractor.extract_all_solutions(\n",
        "                self.retrieval_system.case_ids\n",
        "            )\n",
        "            print(f\"‚úÖ Cached {len(all_solutions)} solutions\")\n",
        "\n",
        "    def majority_vote(self, solutions: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        1. Majority vote: pilih solusi yang paling banyak muncul\n",
        "        \"\"\"\n",
        "        if not solutions:\n",
        "            return \"Tidak ada solusi tersedia\"\n",
        "\n",
        "        # Normalisasi solusi untuk counting\n",
        "        normalized_solutions = []\n",
        "        for sol in solutions:\n",
        "            # Ambil kata kunci utama\n",
        "            sol_lower = sol.lower()\n",
        "\n",
        "            # Extract key decision words\n",
        "            key_words = []\n",
        "            if 'terbukti' in sol_lower and 'tidak' not in sol_lower:\n",
        "                key_words.append('terbukti')\n",
        "            elif 'tidak terbukti' in sol_lower:\n",
        "                key_words.append('tidak_terbukti')\n",
        "\n",
        "            if 'penjara' in sol_lower or 'pidana' in sol_lower:\n",
        "                key_words.append('penjara')\n",
        "            if 'denda' in sol_lower:\n",
        "                key_words.append('denda')\n",
        "            if 'bebas' in sol_lower:\n",
        "                key_words.append('bebas')\n",
        "\n",
        "            normalized = '_'.join(key_words) if key_words else 'unknown'\n",
        "            normalized_solutions.append(normalized)\n",
        "\n",
        "        # Count occurrences\n",
        "        counter = Counter(normalized_solutions)\n",
        "        most_common = counter.most_common(1)[0][0]\n",
        "\n",
        "        # Map back to original solution\n",
        "        for i, norm_sol in enumerate(normalized_solutions):\n",
        "            if norm_sol == most_common:\n",
        "                return solutions[i]\n",
        "\n",
        "        return solutions[0]  # Fallback\n",
        "\n",
        "    def weighted_similarity(self, solutions: List[str], scores: List[float]) -> str:\n",
        "        \"\"\"\n",
        "        2. Weighted similarity: bobot = skor similarity\n",
        "        \"\"\"\n",
        "        if not solutions or not scores:\n",
        "            return \"Tidak ada solusi tersedia\"\n",
        "\n",
        "        # Normalisasi scores\n",
        "        total_score = sum(scores)\n",
        "        if total_score == 0:\n",
        "            return self.majority_vote(solutions)\n",
        "\n",
        "        weights = [score / total_score for score in scores]\n",
        "\n",
        "        # Group solutions by similarity\n",
        "        solution_weights = defaultdict(float)\n",
        "        solution_examples = {}\n",
        "\n",
        "        for sol, weight in zip(solutions, weights):\n",
        "            # Simplify solution for grouping\n",
        "            sol_key = self._simplify_solution(sol)\n",
        "            solution_weights[sol_key] += weight\n",
        "            if sol_key not in solution_examples:\n",
        "                solution_examples[sol_key] = sol\n",
        "\n",
        "        # Pilih solusi dengan weight tertinggi\n",
        "        best_solution_key = max(solution_weights, key=solution_weights.get)\n",
        "        return solution_examples[best_solution_key]\n",
        "\n",
        "    def _simplify_solution(self, solution: str) -> str:\n",
        "        \"\"\"Simplify solution untuk grouping\"\"\"\n",
        "        sol_lower = solution.lower()\n",
        "\n",
        "        if 'tidak terbukti' in sol_lower or 'bebas' in sol_lower:\n",
        "            return 'tidak_terbukti'\n",
        "        elif 'terbukti' in sol_lower:\n",
        "            if 'penjara' in sol_lower and 'denda' in sol_lower:\n",
        "                return 'terbukti_penjara_denda'\n",
        "            elif 'penjara' in sol_lower:\n",
        "                return 'terbukti_penjara'\n",
        "            elif 'denda' in sol_lower:\n",
        "                return 'terbukti_denda'\n",
        "            else:\n",
        "                return 'terbukti'\n",
        "        else:\n",
        "                return 'unknown'\n",
        "\n",
        "    def predict_outcome(self, query: str, k: int = 5, method: str = 'weighted') -> Dict:\n",
        "        \"\"\"\n",
        "        Implementasi Fungsi predict_outcome sesuai spesifikasi\n",
        "        \"\"\"\n",
        "        # Retrieve top-k similar cases\n",
        "        if method == 'weighted':\n",
        "            top_cases_with_scores = self.retrieval_system.retrieve_with_scores(query, k=k)\n",
        "            top_k = [case for case, score in top_cases_with_scores]\n",
        "            scores = [score for case, score in top_cases_with_scores]\n",
        "        else:\n",
        "            top_k = self.retrieval_system.retrieve(query, k=k)\n",
        "            scores = [1.0] * len(top_k)  # Equal weights for majority vote\n",
        "\n",
        "        if not top_k:\n",
        "            return {\n",
        "                'predicted_solution': \"Tidak dapat menemukan kasus serupa\",\n",
        "                'top_cases': [],\n",
        "                'method': method,\n",
        "                'confidence': 0.0\n",
        "            }\n",
        "\n",
        "        # Extract solutions from top-k cases\n",
        "        solutions = []\n",
        "        valid_cases = []\n",
        "        valid_scores = []\n",
        "\n",
        "        for i, case_id in enumerate(top_k):\n",
        "            if case_id in self.solution_extractor.case_solutions:\n",
        "                solution = self.solution_extractor.case_solutions[case_id]\n",
        "                solutions.append(solution)\n",
        "                valid_cases.append(case_id)\n",
        "                valid_scores.append(scores[i])\n",
        "\n",
        "        if not solutions:\n",
        "            return {\n",
        "                'predicted_solution': \"Solusi tidak tersedia untuk kasus serupa\",\n",
        "                'top_cases': top_k,\n",
        "                'method': method,\n",
        "                'confidence': 0.0\n",
        "            }\n",
        "\n",
        "        # Apply prediction algorithm\n",
        "        if method == 'majority':\n",
        "            predicted_solution = self.majority_vote(solutions)\n",
        "        else:  # weighted\n",
        "            predicted_solution = self.weighted_similarity(solutions, valid_scores)\n",
        "\n",
        "        # Calculate confidence\n",
        "        confidence = sum(valid_scores) / len(valid_scores) if valid_scores else 0.0\n",
        "\n",
        "        return {\n",
        "            'predicted_solution': predicted_solution,\n",
        "            'top_cases': valid_cases,\n",
        "            'case_solutions': dict(zip(valid_cases, solutions)),\n",
        "            'similarity_scores': valid_scores,\n",
        "            'method': method,\n",
        "            'confidence': confidence,\n",
        "            'query': query\n",
        "        }\n"
      ],
      "metadata": {
        "id": "KuR1P-CzF_Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Manual"
      ],
      "metadata": {
        "id": "oYNOOeNAGKNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# iv. DEMO MANUAL\n",
        "# 1. Siapkan 5 contoh kasus baru ‚Üí jalankan predict_outcome() ‚Üí\n",
        "#    bandingkan dengan putusan sebenarnya\n",
        "# ============================================================================\n",
        "\n",
        "class ManualDemo:\n",
        "    \"\"\"\n",
        "    iv. Demo Manual\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/korupsi\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = os.path.join(base_dir, \"data\", \"results\")\n",
        "\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        self.predictor = SolutionPredictor(base_dir)\n",
        "\n",
        "        print(\"üß™ iv. DEMO MANUAL\")\n",
        "\n",
        "    def create_demo_cases(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        1. Siapkan 5 contoh kasus baru\n",
        "        \"\"\"\n",
        "        demo_cases = [\n",
        "            {\n",
        "                \"query_id\": \"DEMO_001\",\n",
        "                \"query\": \"korupsi pengadaan alat kesehatan rumah sakit senilai 2 miliar rupiah\",\n",
        "                \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan denda\",\n",
        "                \"description\": \"Korupsi pengadaan medis\"\n",
        "            },\n",
        "            {\n",
        "                \"query_id\": \"DEMO_002\",\n",
        "                \"query\": \"penyuapan kepala dinas untuk mendapatkan izin usaha\",\n",
        "                \"expected_outcome\": \"Terbukti bersalah, pidana penjara\",\n",
        "                \"description\": \"Penyuapan perizinan\"\n",
        "            },\n",
        "            {\n",
        "                \"query_id\": \"DEMO_003\",\n",
        "                \"query\": \"gratifikasi kepada hakim untuk meringankan vonis\",\n",
        "                \"expected_outcome\": \"Terbukti bersalah, pidana penjara\",\n",
        "                \"description\": \"Gratifikasi hakim\"\n",
        "            },\n",
        "            {\n",
        "                \"query_id\": \"DEMO_004\",\n",
        "                \"query\": \"mark up anggaran proyek jalan senilai 500 juta rupiah\",\n",
        "                \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan denda\",\n",
        "                \"description\": \"Mark up proyek infrastruktur\"\n",
        "            },\n",
        "            {\n",
        "                \"query_id\": \"DEMO_005\",\n",
        "                \"query\": \"pencucian uang hasil korupsi melalui investasi properti\",\n",
        "                \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan perampasan aset\",\n",
        "                \"description\": \"Money laundering\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        print(f\"üìù Created {len(demo_cases)} demo cases\")\n",
        "        for case in demo_cases:\n",
        "            print(f\"   {case['query_id']}: {case['description']}\")\n",
        "\n",
        "        return demo_cases\n",
        "\n",
        "    def run_demo(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        2. Jalankan predict_outcome() untuk setiap kasus demo\n",
        "        \"\"\"\n",
        "        demo_cases = self.create_demo_cases()\n",
        "        results = []\n",
        "\n",
        "        print(f\"\\nüîÆ Running prediction demo...\")\n",
        "\n",
        "        for case in demo_cases:\n",
        "            query_id = case['query_id']\n",
        "            query = case['query']\n",
        "            expected = case['expected_outcome']\n",
        "\n",
        "            print(f\"\\n--- {query_id} ---\")\n",
        "            print(f\"Query: {query}\")\n",
        "            print(f\"Expected: {expected}\")\n",
        "\n",
        "            # Test both methods\n",
        "            for method in ['weighted', 'majority']:\n",
        "                try:\n",
        "                    prediction_result = self.predictor.predict_outcome(\n",
        "                        query=query,\n",
        "                        k=5,\n",
        "                        method=method\n",
        "                    )\n",
        "\n",
        "                    predicted_solution = prediction_result['predicted_solution']\n",
        "                    confidence = prediction_result['confidence']\n",
        "                    top_cases = prediction_result['top_cases']\n",
        "\n",
        "                    print(f\"\\n{method.upper()} Method:\")\n",
        "                    print(f\"  Predicted: {predicted_solution[:100]}...\")\n",
        "                    print(f\"  Confidence: {confidence:.3f}\")\n",
        "                    print(f\"  Top cases: {top_cases[:3]}\")\n",
        "\n",
        "                    # Compare with expected\n",
        "                    comparison = self.compare_prediction(predicted_solution, expected)\n",
        "                    print(f\"  Match score: {comparison['score']:.2f}\")\n",
        "\n",
        "                    result = {\n",
        "                        'query_id': query_id,\n",
        "                        'query': query,\n",
        "                        'method': method,\n",
        "                        'predicted_solution': predicted_solution,\n",
        "                        'expected_outcome': expected,\n",
        "                        'confidence': confidence,\n",
        "                        'top_cases': top_cases,\n",
        "                        'match_score': comparison['score'],\n",
        "                        'match_explanation': comparison['explanation']\n",
        "                    }\n",
        "\n",
        "                    results.append(result)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ‚ùå Error: {e}\")\n",
        "\n",
        "                    error_result = {\n",
        "                        'query_id': query_id,\n",
        "                        'query': query,\n",
        "                        'method': method,\n",
        "                        'predicted_solution': f\"Error: {str(e)}\",\n",
        "                        'expected_outcome': expected,\n",
        "                        'confidence': 0.0,\n",
        "                        'top_cases': [],\n",
        "                        'match_score': 0.0,\n",
        "                        'match_explanation': 'Prediction failed'\n",
        "                    }\n",
        "\n",
        "                    results.append(error_result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def compare_prediction(self, predicted: str, expected: str) -> Dict:\n",
        "        \"\"\"\n",
        "        3. Bandingkan dengan putusan sebenarnya\n",
        "        \"\"\"\n",
        "        pred_lower = predicted.lower()\n",
        "        exp_lower = expected.lower()\n",
        "\n",
        "        score = 0.0\n",
        "        explanations = []\n",
        "\n",
        "        # Check for key terms\n",
        "        key_terms = [\n",
        "            ('terbukti', 0.3),\n",
        "            ('tidak terbukti', 0.3),\n",
        "            ('penjara', 0.2),\n",
        "            ('pidana', 0.2),\n",
        "            ('denda', 0.15),\n",
        "            ('bebas', 0.2)\n",
        "        ]\n",
        "\n",
        "        for term, weight in key_terms:\n",
        "            if term in pred_lower and term in exp_lower:\n",
        "                score += weight\n",
        "                explanations.append(f\"‚úÖ Found '{term}'\")\n",
        "            elif term in exp_lower and term not in pred_lower:\n",
        "                explanations.append(f\"‚ùå Missing '{term}'\")\n",
        "            elif term in pred_lower and term not in exp_lower:\n",
        "                explanations.append(f\"‚ö†Ô∏è Extra '{term}'\")\n",
        "\n",
        "        # Bonus for overall direction match\n",
        "        if ('terbukti' in pred_lower and 'terbukti' in exp_lower) or \\\n",
        "           ('tidak terbukti' in pred_lower and ('tidak terbukti' in exp_lower or 'bebas' in exp_lower)):\n",
        "            score += 0.2\n",
        "            explanations.append(\"‚úÖ Overall direction matches\")\n",
        "\n",
        "        score = min(score, 1.0)  # Cap at 1.0\n",
        "\n",
        "        return {\n",
        "            'score': score,\n",
        "            'explanation': '; '.join(explanations)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "zB-UsBWDGFtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# v. OUTPUT\n",
        "# 1. Script 04_predict.py / notebook\n",
        "# 2. File /data/results/predictions.csv berisi:\n",
        "#    query_id predicted_solution top_5_case_ids\n",
        "# ============================================================================\n",
        "\n",
        "class OutputGenerator:\n",
        "    \"\"\"\n",
        "    v. Output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/korupsi\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = os.path.join(base_dir, \"data\", \"results\")\n",
        "\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        print(\"üìä v. OUTPUT\")\n",
        "\n",
        "    def save_predictions_csv(self, results: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        2. File /data/results/predictions.csv berisi:\n",
        "           query_id predicted_solution top_5_case_ids\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        csv_filename = f\"predictions_{timestamp}.csv\"\n",
        "        csv_path = os.path.join(self.results_dir, csv_filename)\n",
        "\n",
        "        # Prepare data for CSV\n",
        "        csv_data = []\n",
        "\n",
        "        for result in results:\n",
        "            # Convert top_cases list to string\n",
        "            top_5_case_ids = ';'.join(result['top_cases'][:5])\n",
        "\n",
        "            csv_row = {\n",
        "                'query_id': result['query_id'],\n",
        "                'query': result['query'],\n",
        "                'method': result['method'],\n",
        "                'predicted_solution': result['predicted_solution'],\n",
        "                'expected_outcome': result['expected_outcome'],\n",
        "                'top_5_case_ids': top_5_case_ids,\n",
        "                'confidence': result['confidence'],\n",
        "                'match_score': result['match_score'],\n",
        "                'match_explanation': result['match_explanation']\n",
        "            }\n",
        "\n",
        "            csv_data.append(csv_row)\n",
        "\n",
        "        # Save to CSV\n",
        "        df = pd.DataFrame(csv_data)\n",
        "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
        "\n",
        "        print(f\"üìÑ Predictions saved: {csv_filename}\")\n",
        "        print(f\"   Records: {len(csv_data)}\")\n",
        "        print(f\"   Columns: {list(df.columns)}\")\n",
        "\n",
        "        return csv_path\n",
        "\n",
        "    def save_detailed_results(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Save detailed results as JSON\"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        json_filename = f\"detailed_predictions_{timestamp}.json\"\n",
        "        json_path = os.path.join(self.results_dir, json_filename)\n",
        "\n",
        "        detailed_data = {\n",
        "            'metadata': {\n",
        "                'generated_at': datetime.now().isoformat(),\n",
        "                'total_predictions': len(results),\n",
        "                'methods_used': list(set([r['method'] for r in results])),\n",
        "                'version': 'solution_reuse_v1'\n",
        "            },\n",
        "            'results': results\n",
        "        }\n",
        "\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(detailed_data, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "        print(f\"üìÑ Detailed results saved: {json_filename}\")\n",
        "\n",
        "        return json_path\n",
        "\n",
        "    def generate_summary_report(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Generate summary report\"\"\"\n",
        "        report = []\n",
        "        report.append(\"=\" * 70)\n",
        "        report.append(\"üîÆ TAHAP 4 - SOLUTION REUSE - SUMMARY REPORT\")\n",
        "        report.append(\"=\" * 70)\n",
        "        report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Overall statistics\n",
        "        total_predictions = len(results)\n",
        "        successful_predictions = len([r for r in results if 'Error' not in r['predicted_solution']])\n",
        "        avg_confidence = np.mean([r['confidence'] for r in results if r['confidence'] > 0])\n",
        "        avg_match_score = np.mean([r['match_score'] for r in results])\n",
        "\n",
        "        report.append(\"üìä OVERALL STATISTICS:\")\n",
        "        report.append(f\"  Total predictions: {total_predictions}\")\n",
        "        report.append(f\"  Successful predictions: {successful_predictions} ({successful_predictions/total_predictions*100:.1f}%)\")\n",
        "        report.append(f\"  Average confidence: {avg_confidence:.3f}\")\n",
        "        report.append(f\"  Average match score: {avg_match_score:.3f}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Method comparison\n",
        "        methods = list(set([r['method'] for r in results]))\n",
        "        report.append(\"üîß METHOD COMPARISON:\")\n",
        "\n",
        "        for method in methods:\n",
        "            method_results = [r for r in results if r['method'] == method]\n",
        "            method_confidence = np.mean([r['confidence'] for r in method_results if r['confidence'] > 0])\n",
        "            method_match = np.mean([r['match_score'] for r in method_results])\n",
        "\n",
        "            report.append(f\"  {method.upper()}:\")\n",
        "            report.append(f\"    Avg Confidence: {method_confidence:.3f}\")\n",
        "            report.append(f\"    Avg Match Score: {method_match:.3f}\")\n",
        "\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Best predictions\n",
        "        report.append(\"üèÜ BEST PREDICTIONS:\")\n",
        "        best_results = sorted([r for r in results if r['match_score'] > 0],\n",
        "                             key=lambda x: x['match_score'], reverse=True)[:3]\n",
        "\n",
        "        for i, result in enumerate(best_results, 1):\n",
        "            report.append(f\"  {i}. {result['query_id']} ({result['method']})\")\n",
        "            report.append(f\"     Query: {result['query'][:50]}...\")\n",
        "            report.append(f\"     Match Score: {result['match_score']:.3f}\")\n",
        "            report.append(f\"     Confidence: {result['confidence']:.3f}\")\n",
        "\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Performance assessment\n",
        "        if avg_match_score >= 0.7:\n",
        "            report.append(\"üéâ EXCELLENT: System performing very well!\")\n",
        "        elif avg_match_score >= 0.5:\n",
        "            report.append(\"‚úÖ GOOD: System performing adequately\")\n",
        "        elif avg_match_score >= 0.3:\n",
        "            report.append(\"‚ö†Ô∏è FAIR: System needs improvement\")\n",
        "        else:\n",
        "            report.append(\"‚ùå POOR: System requires significant work\")\n",
        "\n",
        "        report.append(\"=\" * 70)\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "class SolutionReuseSystem:\n",
        "    \"\"\"\n",
        "    Main class untuk Tahap 4 - Solution Reuse\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/korupsi\"):\n",
        "        self.base_dir = base_dir\n",
        "\n",
        "        print(\"üîÆ TAHAP 4 - SOLUTION REUSE\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Tujuan: Gunakan putusan lama sebagai dasar pencarian untuk kasus baru\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Initialize components\n",
        "        self.solution_extractor = SolutionExtractor(base_dir)\n",
        "        self.predictor = SolutionPredictor(base_dir)\n",
        "        self.demo = ManualDemo(base_dir)\n",
        "        self.output_generator = OutputGenerator(base_dir)\n",
        "\n",
        "    def run_complete_solution_reuse(self) -> bool:\n",
        "        \"\"\"\n",
        "        Jalankan semua tahap solution reuse\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"\\nüîÆ Running complete solution reuse process...\")\n",
        "\n",
        "            # iv. Demo Manual\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"üß™ iv. DEMO MANUAL\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            demo_results = self.demo.run_demo()\n",
        "\n",
        "            if not demo_results:\n",
        "                print(\"‚ùå Demo failed - no results generated\")\n",
        "                return False\n",
        "\n",
        "            # v. Output\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"üìä v. OUTPUT\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            # Save CSV\n",
        "            csv_path = self.output_generator.save_predictions_csv(demo_results)\n",
        "\n",
        "            # Save detailed JSON\n",
        "            json_path = self.output_generator.save_detailed_results(demo_results)\n",
        "\n",
        "            # Generate and show report\n",
        "            report = self.output_generator.generate_summary_report(demo_results)\n",
        "            print(f\"\\n{report}\")\n",
        "\n",
        "            # Final success message\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"‚úÖ TAHAP 4 - SOLUTION REUSE COMPLETED!\")\n",
        "            print(\"üìÅ Output files created:\")\n",
        "            print(f\"   - {os.path.basename(csv_path)}\")\n",
        "            print(f\"   - {os.path.basename(json_path)}\")\n",
        "            print(\"üîÆ Solution reuse system ready for production!\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in solution reuse process: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return False\n",
        "\n",
        "def test_individual_components():\n",
        "    \"\"\"Test individual components untuk debugging\"\"\"\n",
        "    print(\"üß™ TESTING INDIVIDUAL COMPONENTS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/korupsi\"\n",
        "\n",
        "    # Test 1: Retrieval System\n",
        "    print(\"\\n1. Testing Retrieval System...\")\n",
        "    try:\n",
        "        retrieval = RetrievalSystem(base_dir)\n",
        "        if retrieval.case_ids:\n",
        "            test_query = \"korupsi pengadaan\"\n",
        "            results = retrieval.retrieve(test_query, k=3)\n",
        "            print(f\"‚úÖ Retrieval working: {len(results)} results for '{test_query}'\")\n",
        "        else:\n",
        "            print(\"‚ùå Retrieval system has no cases\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Retrieval test failed: {e}\")\n",
        "\n",
        "    # Test 2: Solution Extractor\n",
        "    print(\"\\n2. Testing Solution Extractor...\")\n",
        "    try:\n",
        "        extractor = SolutionExtractor(base_dir)\n",
        "        if extractor.load_case_metadata():\n",
        "            sample_cases = list(extractor.case_metadata.keys())[:3]\n",
        "            solutions = extractor.extract_all_solutions(sample_cases)\n",
        "            print(f\"‚úÖ Extraction working: {len(solutions)} solutions extracted\")\n",
        "        else:\n",
        "            print(\"‚ùå Cannot load case metadata\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Extraction test failed: {e}\")\n",
        "\n",
        "    # Test 3: Predictor\n",
        "    print(\"\\n3. Testing Predictor...\")\n",
        "    try:\n",
        "        predictor = SolutionPredictor(base_dir)\n",
        "        test_query = \"penyuapan pejabat\"\n",
        "        result = predictor.predict_outcome(test_query, k=3)\n",
        "        print(f\"‚úÖ Prediction working: '{result['predicted_solution'][:50]}...'\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Prediction test failed: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fungsi utama untuk Tahap 4 - Solution Reuse\n",
        "    \"\"\"\n",
        "    print(\"üöÄ MULAI TAHAP 4 - SOLUTION REUSE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    try:\n",
        "        # Optional: Test individual components first\n",
        "        # test_individual_components()\n",
        "\n",
        "        # Run complete solution reuse system\n",
        "        system = SolutionReuseSystem()\n",
        "        success = system.run_complete_solution_reuse()\n",
        "\n",
        "        if success:\n",
        "            print(f\"\\nüéâ TAHAP 4 BERHASIL!\")\n",
        "            print(\"‚ú® Yang telah diselesaikan:\")\n",
        "            print(\"  ‚úÖ i. Ekstrak Solusi dari kasus top-k\")\n",
        "            print(\"  ‚úÖ ii. Algoritma Prediksi (majority vote & weighted similarity)\")\n",
        "            print(\"  ‚úÖ iii. Implementasi Fungsi predict_outcome()\")\n",
        "            print(\"  ‚úÖ iv. Demo Manual dengan 5 contoh kasus\")\n",
        "            print(\"  ‚úÖ v. Output CSV dan JSON hasil prediksi\")\n",
        "            print(\"üîÆ Solution reuse system siap digunakan!\")\n",
        "        else:\n",
        "            print(\"\\n‚ùå Tahap 4 gagal diselesaikan\")\n",
        "            print(\"üîß Jalankan test_individual_components() untuk debugging\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nüí• ERROR: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# ============================================================================\n",
        "# ADDITIONAL UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def quick_predict(query: str, base_dir=\"/content/drive/MyDrive/korupsi\") -> str:\n",
        "    \"\"\"\n",
        "    Quick prediction function untuk testing cepat\n",
        "\n",
        "    Usage:\n",
        "    result = quick_predict(\"korupsi pengadaan barang\")\n",
        "    print(result)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        predictor = SolutionPredictor(base_dir)\n",
        "        result = predictor.predict_outcome(query, k=5, method='weighted')\n",
        "        return result['predicted_solution']\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def batch_predict(queries: List[str], base_dir=\"/content/drive/MyDrive/korupsi\") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Batch prediction untuk multiple queries\n",
        "\n",
        "    Usage:\n",
        "    queries = [\"korupsi pengadaan\", \"penyuapan hakim\", \"pencucian uang\"]\n",
        "    results = batch_predict(queries)\n",
        "    \"\"\"\n",
        "    predictor = SolutionPredictor(base_dir)\n",
        "    results = []\n",
        "\n",
        "    for i, query in enumerate(queries):\n",
        "        try:\n",
        "            result = predictor.predict_outcome(query, k=5, method='weighted')\n",
        "            result['query_id'] = f\"BATCH_{i+1:03d}\"\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            error_result = {\n",
        "                'query_id': f\"BATCH_{i+1:03d}\",\n",
        "                'query': query,\n",
        "                'predicted_solution': f\"Error: {str(e)}\",\n",
        "                'confidence': 0.0,\n",
        "                'top_cases': []\n",
        "            }\n",
        "            results.append(error_result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def interactive_demo(base_dir=\"/content/drive/MyDrive/korupsi\"):\n",
        "    \"\"\"\n",
        "    Interactive demo untuk testing manual\n",
        "    \"\"\"\n",
        "    print(\"üîÆ INTERACTIVE SOLUTION REUSE DEMO\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Masukkan query kasus hukum (atau 'quit' untuk keluar)\")\n",
        "\n",
        "    predictor = SolutionPredictor(base_dir)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nüîç Query: \").strip()\n",
        "\n",
        "        if query.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            print(f\"üîÆ Predicting for: '{query}'\")\n",
        "\n",
        "            # Test both methods\n",
        "            for method in ['weighted', 'majority']:\n",
        "                result = predictor.predict_outcome(query, k=5, method=method)\n",
        "\n",
        "                print(f\"\\n{method.upper()} METHOD:\")\n",
        "                print(f\"Prediction: {result['predicted_solution']}\")\n",
        "                print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "                print(f\"Top cases: {result['top_cases'][:3]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "    print(\"üëã Demo selesai!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAV67qQyHv2f",
        "outputId": "391904e5-c75b-40d0-cdd6-708a20e255a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ MULAI TAHAP 4 - SOLUTION REUSE\n",
            "======================================================================\n",
            "üîÆ TAHAP 4 - SOLUTION REUSE\n",
            "============================================================\n",
            "Tujuan: Gunakan putusan lama sebagai dasar pencarian untuk kasus baru\n",
            "============================================================\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üîç Loading retrieval components...\n",
            "‚úÖ Loaded: 114 cases, 16,580 vocab\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üíæ Initializing solution cache...\n",
            "\n",
            "üìÑ Extracting solutions for 114 cases...\n",
            "‚úÖ Loaded metadata for 114 cases\n",
            "‚úÖ Extracted 114 solutions\n",
            "   case_2024_TK1_Putusan_PN_SURABAYA_Nomor_85_Pid_Sus-TPK_2024_PN_Sby_Tanggal_31_Desember_2024__Penuntut_Umum_Martina_Peristyanti__S_H___MBATerdakwa_MEGA_YUNAN_RAKHMANA: amar putusan ini;menimbang, bahwa selanjutnya terhadap barang bukti yang diajukanoleh penuntut umum ...\n",
            "   case_2024_TK1_Putusan_PN_SURABAYA_Nomor_86_Pid_Sus-TPK_2024_PN_Sby_Tanggal_31_Desember_2024__Penuntut_Umum_Martina_Peristyanti__S_H___MBATerdakwa_SUJARWO_Bin_JIMIN: amar putusan denganpemahaman bahwa korupsi adalah suatu kejahatan yang harus ditanggulangisecara ext...\n",
            "   case_2024_TK1_Putusan_PN_SURABAYA_Nomor_105_Pid_Sus-TPK_2024_PN_Sby_Tanggal_23_Desember_2024__Penuntut_Umum_DIAN_PRANATA_DEPARI__S_H__M_HTerdakwa_Rian_Mahendra_Bin_Achmad_Wardoyo_Alm: amar putusan perkara ini.menimbang bahwa oleh karena ancaman pidana pasal yang terbuktiadalah kumula...\n",
            "‚úÖ Cached 114 solutions\n",
            "üîÆ ii. ALGORITMA PREDIKSI\n",
            "üîç Loading retrieval components...\n",
            "‚úÖ Loaded: 114 cases, 16,580 vocab\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üíæ Initializing solution cache...\n",
            "\n",
            "üìÑ Extracting solutions for 114 cases...\n",
            "‚úÖ Loaded metadata for 114 cases\n",
            "‚úÖ Extracted 114 solutions\n",
            "   case_2024_TK1_Putusan_PN_SURABAYA_Nomor_85_Pid_Sus-TPK_2024_PN_Sby_Tanggal_31_Desember_2024__Penuntut_Umum_Martina_Peristyanti__S_H___MBATerdakwa_MEGA_YUNAN_RAKHMANA: amar putusan ini;menimbang, bahwa selanjutnya terhadap barang bukti yang diajukanoleh penuntut umum ...\n",
            "   case_2024_TK1_Putusan_PN_SURABAYA_Nomor_86_Pid_Sus-TPK_2024_PN_Sby_Tanggal_31_Desember_2024__Penuntut_Umum_Martina_Peristyanti__S_H___MBATerdakwa_SUJARWO_Bin_JIMIN: amar putusan denganpemahaman bahwa korupsi adalah suatu kejahatan yang harus ditanggulangisecara ext...\n",
            "   case_2024_TK1_Putusan_PN_SURABAYA_Nomor_105_Pid_Sus-TPK_2024_PN_Sby_Tanggal_23_Desember_2024__Penuntut_Umum_DIAN_PRANATA_DEPARI__S_H__M_HTerdakwa_Rian_Mahendra_Bin_Achmad_Wardoyo_Alm: amar putusan perkara ini.menimbang bahwa oleh karena ancaman pidana pasal yang terbuktiadalah kumula...\n",
            "‚úÖ Cached 114 solutions\n",
            "üîÆ ii. ALGORITMA PREDIKSI\n",
            "üß™ iv. DEMO MANUAL\n",
            "üìä v. OUTPUT\n",
            "\n",
            "üîÆ Running complete solution reuse process...\n",
            "\n",
            "==================================================\n",
            "üß™ iv. DEMO MANUAL\n",
            "==================================================\n",
            "üìù Created 5 demo cases\n",
            "   DEMO_001: Korupsi pengadaan medis\n",
            "   DEMO_002: Penyuapan perizinan\n",
            "   DEMO_003: Gratifikasi hakim\n",
            "   DEMO_004: Mark up proyek infrastruktur\n",
            "   DEMO_005: Money laundering\n",
            "\n",
            "üîÆ Running prediction demo...\n",
            "\n",
            "--- DEMO_001 ---\n",
            "Query: korupsi pengadaan alat kesehatan rumah sakit senilai 2 miliar rupiah\n",
            "Expected: Terbukti bersalah, pidana penjara dan denda\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: mengadili perkara-perkara perdata permohonan pada peradilan tingkat pertama telah menetapkansebagai ...\n",
            "  Confidence: 0.025\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_34_Pid_Sus-TPK_2024_PN_Sby_Tanggal_20_September_2024__Penuntut_Umum_ARIO_WIBOWO__S_H___M_H_Terdakwa_HENY_WULANDARI__S_T_', 'case_2025_TK1_Putusan_PN_JAKARTA_UTARA_Nomor_451_Pdt_P_2025_PN_Jkt_Utr_Tanggal_11_Juni_2025__Pemohon_RICE_DAMAYANTI', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_138_Pid_Sus-TPK_2023_PN_Sby_Tanggal_17_April_2024__Penuntut_Umum_PUTU_EKA_WISNIATI__S_H_Terdakwa_HENRY_KUSNOHARDJO']\n",
            "  Match score: 0.00\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan ini;menimbang, bahwa menurut ketentuan pasal 18 ayat (1) huruf bundang-undang ri nomor ...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_34_Pid_Sus-TPK_2024_PN_Sby_Tanggal_20_September_2024__Penuntut_Umum_ARIO_WIBOWO__S_H___M_H_Terdakwa_HENY_WULANDARI__S_T_', 'case_2025_TK1_Putusan_PN_JAKARTA_UTARA_Nomor_451_Pdt_P_2025_PN_Jkt_Utr_Tanggal_11_Juni_2025__Pemohon_RICE_DAMAYANTI', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_138_Pid_Sus-TPK_2023_PN_Sby_Tanggal_17_April_2024__Penuntut_Umum_PUTU_EKA_WISNIATI__S_H_Terdakwa_HENRY_KUSNOHARDJO']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_002 ---\n",
            "Query: penyuapan kepala dinas untuk mendapatkan izin usaha\n",
            "Expected: Terbukti bersalah, pidana penjara\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan perkara ini.menimbang, bahwa oleh karena terdakwa dijatuhi pidana maka haruslahdibebani...\n",
            "  Confidence: 0.049\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_103_Pid_Sus-TPK_2024_PN_Sby_Tanggal_23_Desember_2024__Penuntut_Umum_DIAN_PRANATA_DEPARI__S_H__M_HTerdakwa_H__Munandar__SP___M_M_Bin_Alm__Adjib', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_38_Pid_Sus-TPK_2024_PN_Sby_Tanggal_2_Oktober_2024__Penuntut_Umum_ALIFIN_NURAHMANA_WANDA__S_HTerdakwa_Dra__MALAHATUL_FARDAH__M_M_', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_110_Pid_Sus-TPK_2024_PN_Sby_Tanggal_23_Desember_2024__Penuntut_Umum_Gilang_GemilangTerdakwa_AHMAD_MUHDLOR']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan ini. menimbang, bahwa terhadap barang bukti berupa 1 (satu) buah amplopberwarna coklat ...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_103_Pid_Sus-TPK_2024_PN_Sby_Tanggal_23_Desember_2024__Penuntut_Umum_DIAN_PRANATA_DEPARI__S_H__M_HTerdakwa_H__Munandar__SP___M_M_Bin_Alm__Adjib', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_38_Pid_Sus-TPK_2024_PN_Sby_Tanggal_2_Oktober_2024__Penuntut_Umum_ALIFIN_NURAHMANA_WANDA__S_HTerdakwa_Dra__MALAHATUL_FARDAH__M_M_', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_110_Pid_Sus-TPK_2024_PN_Sby_Tanggal_23_Desember_2024__Penuntut_Umum_Gilang_GemilangTerdakwa_AHMAD_MUHDLOR']\n",
            "  Match score: 0.00\n",
            "\n",
            "--- DEMO_003 ---\n",
            "Query: gratifikasi kepada hakim untuk meringankan vonis\n",
            "Expected: Terbukti bersalah, pidana penjara\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan ini;menimbang, bahwa terhadap barang bukti yang diajukan di persidanganuntuk selanjutny...\n",
            "  Confidence: 0.032\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_142_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H___M_H_Terdakwa_LIEM_SUSILOWATI', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_143_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H__M_H_Terdakwa_LIAUW_INGGARWATI', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_37_Pid_Sus-TPK_2024_PN_Sby_Tanggal_2_Oktober_2024__Penuntut_Umum_ALIFIN_NURAHMANA_WANDA__S_HTerdakwa_RYAN_FIBRIANTO']\n",
            "  Match score: 0.00\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan ini;menimbang, bahwa dalam perkara ini terhadap terdakwa telah dikenakanpenangkapan dan...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_142_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H___M_H_Terdakwa_LIEM_SUSILOWATI', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_143_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H__M_H_Terdakwa_LIAUW_INGGARWATI', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_37_Pid_Sus-TPK_2024_PN_Sby_Tanggal_2_Oktober_2024__Penuntut_Umum_ALIFIN_NURAHMANA_WANDA__S_HTerdakwa_RYAN_FIBRIANTO']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_004 ---\n",
            "Query: mark up anggaran proyek jalan senilai 500 juta rupiah\n",
            "Expected: Terbukti bersalah, pidana penjara dan denda\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan di bawah ini adalah sudah patut dan adil setimpaldengan kesalahan terdakwa dalam perkar...\n",
            "  Confidence: 0.024\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_65_Pid_Sus-TPK_2024_PN_Sby_Tanggal_19_Nopember_2024__Penuntut_Umum_Moch__Taufiq_Ismail__S_HTerdakwa_MUSTAQIM__S_T__BIN_MUSLIMIN_HAG_ALM', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_119_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H__M_H_Terdakwa_Drs__Wonggo_Prayitno__MM_', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_138_Pid_Sus-TPK_2023_PN_Sby_Tanggal_17_April_2024__Penuntut_Umum_PUTU_EKA_WISNIATI__S_H_Terdakwa_HENRY_KUSNOHARDJO']\n",
            "  Match score: 0.40\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan di bawah ini adalah sudah patut dan adil setimpaldengan kesalahan terdakwa dalam perkar...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_65_Pid_Sus-TPK_2024_PN_Sby_Tanggal_19_Nopember_2024__Penuntut_Umum_Moch__Taufiq_Ismail__S_HTerdakwa_MUSTAQIM__S_T__BIN_MUSLIMIN_HAG_ALM', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_119_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H__M_H_Terdakwa_Drs__Wonggo_Prayitno__MM_', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_138_Pid_Sus-TPK_2023_PN_Sby_Tanggal_17_April_2024__Penuntut_Umum_PUTU_EKA_WISNIATI__S_H_Terdakwa_HENRY_KUSNOHARDJO']\n",
            "  Match score: 0.40\n",
            "\n",
            "--- DEMO_005 ---\n",
            "Query: pencucian uang hasil korupsi melalui investasi properti\n",
            "Expected: Terbukti bersalah, pidana penjara dan perampasan aset\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan ini;menimbang, bahwa terhadap barang bukti yang diajukan di persidanganuntuk selanjutny...\n",
            "  Confidence: 0.026\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_142_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H___M_H_Terdakwa_LIEM_SUSILOWATI', 'case_2025_TK1_Putusan_PN_JAKARTA_UTARA_Nomor_440_Pdt_P_2025_PN_Jkt_Utr_Tanggal_11_Juni_2025__Pemohon_MAYMUNAH', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_143_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H__M_H_Terdakwa_LIAUW_INGGARWATI']\n",
            "  Match score: 0.00\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: amar putusan ini;menimbang, bahwa terhadap barang bukti yang diajukan di persidanganuntuk selanjutny...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2024_TK1_Putusan_PN_SURABAYA_Nomor_142_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H___M_H_Terdakwa_LIEM_SUSILOWATI', 'case_2025_TK1_Putusan_PN_JAKARTA_UTARA_Nomor_440_Pdt_P_2025_PN_Jkt_Utr_Tanggal_11_Juni_2025__Pemohon_MAYMUNAH', 'case_2024_TK1_Putusan_PN_SURABAYA_Nomor_143_Pid_Sus-TPK_2023_PN_Sby_Tanggal_5_Maret_2024__Penuntut_Umum_NUR_RACHMANSYAH__S_H__M_H_Terdakwa_LIAUW_INGGARWATI']\n",
            "  Match score: 0.00\n",
            "\n",
            "==================================================\n",
            "üìä v. OUTPUT\n",
            "==================================================\n",
            "üìÑ Predictions saved: predictions_20250625_172608.csv\n",
            "   Records: 10\n",
            "   Columns: ['query_id', 'query', 'method', 'predicted_solution', 'expected_outcome', 'top_5_case_ids', 'confidence', 'match_score', 'match_explanation']\n",
            "üìÑ Detailed results saved: detailed_predictions_20250625_172608.json\n",
            "\n",
            "======================================================================\n",
            "üîÆ TAHAP 4 - SOLUTION REUSE - SUMMARY REPORT\n",
            "======================================================================\n",
            "Generated: 2025-06-25 17:26:08\n",
            "\n",
            "üìä OVERALL STATISTICS:\n",
            "  Total predictions: 10\n",
            "  Successful predictions: 10 (100.0%)\n",
            "  Average confidence: 0.516\n",
            "  Average match score: 0.140\n",
            "\n",
            "üîß METHOD COMPARISON:\n",
            "  MAJORITY:\n",
            "    Avg Confidence: 1.000\n",
            "    Avg Match Score: 0.160\n",
            "  WEIGHTED:\n",
            "    Avg Confidence: 0.031\n",
            "    Avg Match Score: 0.120\n",
            "\n",
            "üèÜ BEST PREDICTIONS:\n",
            "  1. DEMO_004 (weighted)\n",
            "     Query: mark up anggaran proyek jalan senilai 500 juta rup...\n",
            "     Match Score: 0.400\n",
            "     Confidence: 0.024\n",
            "  2. DEMO_004 (majority)\n",
            "     Query: mark up anggaran proyek jalan senilai 500 juta rup...\n",
            "     Match Score: 0.400\n",
            "     Confidence: 1.000\n",
            "  3. DEMO_001 (majority)\n",
            "     Query: korupsi pengadaan alat kesehatan rumah sakit senil...\n",
            "     Match Score: 0.200\n",
            "     Confidence: 1.000\n",
            "\n",
            "‚ùå POOR: System requires significant work\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "‚úÖ TAHAP 4 - SOLUTION REUSE COMPLETED!\n",
            "üìÅ Output files created:\n",
            "   - predictions_20250625_172608.csv\n",
            "   - detailed_predictions_20250625_172608.json\n",
            "üîÆ Solution reuse system ready for production!\n",
            "============================================================\n",
            "\n",
            "üéâ TAHAP 4 BERHASIL!\n",
            "‚ú® Yang telah diselesaikan:\n",
            "  ‚úÖ i. Ekstrak Solusi dari kasus top-k\n",
            "  ‚úÖ ii. Algoritma Prediksi (majority vote & weighted similarity)\n",
            "  ‚úÖ iii. Implementasi Fungsi predict_outcome()\n",
            "  ‚úÖ iv. Demo Manual dengan 5 contoh kasus\n",
            "  ‚úÖ v. Output CSV dan JSON hasil prediksi\n",
            "üîÆ Solution reuse system siap digunakan!\n"
          ]
        }
      ]
    }
  ]
}
